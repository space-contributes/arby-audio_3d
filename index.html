<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Arby Audio - 3D Spatial Audio Engine</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
            min-height: 100vh;
            padding: 20px;
            color: #fff;
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
        }

        header {
            text-align: center;
            margin-bottom: 40px;
        }

        .brand-logo {
            font-size: 3.5em;
            font-weight: 900;
            background: linear-gradient(135deg, #e94560, #f39c12, #e94560);
            background-size: 200% auto;
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            animation: gradient 3s ease infinite;
            letter-spacing: -2px;
        }

        @keyframes gradient {
            0%, 100% { background-position: 0% 50%; }
            50% { background-position: 100% 50%; }
        }

        .brand-tagline {
            font-size: 1.1em;
            opacity: 0.9;
            margin-top: 10px;
            color: #f39c12;
        }

        .main-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin-bottom: 20px;
        }

        .panel {
            background: rgba(255, 255, 255, 0.05);
            backdrop-filter: blur(10px);
            border-radius: 15px;
            padding: 25px;
            border: 1px solid rgba(233, 69, 96, 0.3);
        }

        .panel h2 {
            font-size: 1.5em;
            margin-bottom: 20px;
            color: #e94560;
        }

        .upload-zone {
            border: 3px dashed rgba(233, 69, 96, 0.4);
            border-radius: 10px;
            padding: 40px;
            text-align: center;
            cursor: pointer;
            transition: all 0.3s;
            margin-bottom: 20px;
            background: rgba(233, 69, 96, 0.05);
        }

        .upload-zone:hover {
            border-color: #e94560;
            background: rgba(233, 69, 96, 0.1);
        }

        input[type="file"] {
            display: none;
        }

        .control-group {
            margin-bottom: 20px;
        }

        .control-group label {
            display: block;
            margin-bottom: 8px;
            font-weight: 500;
            color: #f39c12;
        }
       
        #progressBarFill {
    height: 100%;
    background: linear-gradient(90deg, #e94560, #f39c12);
    width: 0%;
    transition: width 0.3s;
    text-align: center;
    color: white;
    font-size: 0.8em;
}

        .input-row {
            display: flex;
            align-items: center;
            gap: 10px;
        }

        input[type="range"] {
            flex: 1;
            height: 6px;
            border-radius: 3px;
            background: rgba(233, 69, 96, 0.3);
            outline: none;
            -webkit-appearance: none;
        }

        input[type="range"]::-webkit-slider-thumb {
            -webkit-appearance: none;
            width: 20px;
            height: 20px;
            border-radius: 50%;
            background: linear-gradient(135deg, #e94560, #f39c12);
            cursor: pointer;
        }

        input[type="number"] {
            width: 100px;
            padding: 8px;
            background: rgba(255, 255, 255, 0.1);
            border: 1px solid rgba(233, 69, 96, 0.3);
            border-radius: 5px;
            color: white;
            font-size: 0.9em;
            text-align: center;
        }

        .value-display {
            display: inline-block;
            background: rgba(233, 69, 96, 0.2);
            padding: 6px 12px;
            border-radius: 5px;
            font-size: 0.9em;
            min-width: 80px;
            text-align: center;
        }

        .auto-badge {
            display: inline-block;
            background: linear-gradient(135deg, #f39c12, #e67e22);
            color: white;
            padding: 3px 10px;
            border-radius: 12px;
            font-size: 0.7em;
            font-weight: 700;
            margin-left: 8px;
        }

        button {
            background: linear-gradient(135deg, #e94560 0%, #f39c12 100%);
            color: white;
            border: none;
            padding: 12px 30px;
            border-radius: 8px;
            font-size: 1em;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
            margin-right: 10px;
            margin-bottom: 10px;
        }

        button:hover:not(:disabled) {
            transform: translateY(-2px);
        }

        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .checkbox-group {
            margin: 15px 0;
            display: flex;
            align-items: center;
            gap: 10px;
            padding: 10px;
            background: rgba(233, 69, 96, 0.05);
            border-radius: 8px;
        }

        input[type="checkbox"] {
            width: 20px;
            height: 20px;
            cursor: pointer;
            accent-color: #e94560;
        }

        select {
            background: rgba(233, 69, 96, 0.2);
            border: 1px solid rgba(233, 69, 96, 0.3);
            color: white;
            padding: 8px 12px;
            border-radius: 5px;
            cursor: pointer;
            outline: none;
        }

        select option {
            background: #16213e;
        }

        .info, .success, .rate-limit-info {
            padding: 12px;
            border-radius: 5px;
            margin-top: 15px;
            border-left: 4px solid;
        }

        .info {
            background: rgba(52, 152, 219, 0.2);
            border-color: #3498db;
        }

        .success {
            background: rgba(46, 204, 113, 0.2);
            border-color: #2ecc71;
        }

        .rate-limit-info {
            background: rgba(243, 156, 18, 0.2);
            border-color: #f39c12;
        }

        .progress {
            height: 6px;
            background: rgba(233, 69, 96, 0.2);
            border-radius: 3px;
            overflow: hidden;
            margin-top: 10px;
        }

        .progress-bar {
            height: 100%;
            background: linear-gradient(90deg, #e94560, #f39c12);
            width: 0%;
            transition: width 0.3s;
        }

        .status {
            background: rgba(0, 0, 0, 0.5);
            padding: 15px;
            border-radius: 8px;
            margin-top: 15px;
            font-family: monospace;
            font-size: 0.9em;
        }

        .status-item {
            margin: 5px 0;
            display: flex;
            justify-content: space-between;
        }

        .visualizer {
            background: rgba(0, 0, 0, 0.5);
            border-radius: 10px;
            height: 200px;
            margin-top: 20px;
        }

        canvas {
            width: 100%;
            height: 100%;
        }

        .speaker-map {
            display: grid;
            grid-template-columns: repeat(4, 1fr);
            gap: 10px;
            margin-top: 15px;
        }

        .speaker {
            background: rgba(233, 69, 96, 0.1);
            padding: 10px;
            border-radius: 8px;
            text-align: center;
            font-size: 0.85em;
            border: 2px solid rgba(233, 69, 96, 0.3);
        }

        @media (max-width: 968px) {
            .main-grid {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <div class="brand-logo">ARBY AUDIO</div>
            <p class="brand-tagline">-- Available at <a class="brand-logo" href="https://github.com/space-contributes/arby-audio_3d/">GitHub Project Link </a>, | Physics-Based 3D Spatial Audio | 7.1.4 @ 96kHz 32-bit |
             </p>
        </header>

        <div class="main-grid">
            <div class="panel">
                <h2>üìÅ Audio Input</h2>
                <div class="upload-zone" id="uploadZone">
                    <div style="font-size: 3em;">üéß</div>
                    <p style="font-size: 1.2em;">Drop audio file or click</p>
                    <p style="opacity: 0.7; font-size: 0.9em;">WAV, MP3, FLAC, OGG, MP4, WEBM, AVI</p>
                </div>
                <input type="file" id="fileInput" accept=".wav,.mp3,.flac,.ogg,.m4a" />
                <div class="info">
                    <strong>üîí Privacy:</strong> All processing in-browser. No uploads.
                </div>
                <div class="rate-limit-info" id="rateLimitInfo" style="display: none;">
                    <strong>‚è±Ô∏è</strong> <span id="rateLimitText"></span>
                </div>
                <div id="fileInfo" style="display: none; margin-top: 15px; padding: 15px; background: rgba(0,0,0,0.5); border-radius: 8px;">
                    <div class="status-item"><span>üìÑ File:</span><span id="fileName">-</span></div>
                    <div class="status-item"><span>‚è±Ô∏è Duration:</span><span id="fileDuration">-</span></div>
                    <div class="status-item"><span>üìä Rate:</span><span id="fileSampleRate">-</span></div>
                    <div class="status-item"><span>üîä Channels:</span><span id="fileChannels">-</span></div>
                </div>
            </div>
<!-- Insert Video Input Panel Here -->
    <div class="panel">
        <h2>üé• Video Input</h2>
        <div class="upload-zone" id="videoUploadZone">
            <div style="font-size: 3em;">üé¨</div>
            <p style="font-size: 1.2em;">Drop video file or click</p>
            <p style="opacity: 0.7; font-size: 0.9em;">MP4, WEBM, AVI</p>
        </div>
        <input type="file" id="videoUpload" accept=".mp4,.webm,.avi" />
        <video id="videoPreview" controls style="display: none; width: 100%; max-height: 300px; margin-top: 10px;"></video>
        <canvas id="canvas" style="display: none;"></canvas>
        <div class="progress" id="progressBar" style="display: none;">
            <div class="progress-bar" id="progressBarFill"></div>
        </div>
    </div>
            <div class="panel">
                <h2>üéöÔ∏è Room Configuration</h2>
                <div style="background: rgba(0,0,0,0.3); padding: 12px; border-radius: 8px; margin-bottom: 20px;">
                    <strong>üìê Preset:</strong> 
                    <select id="roomPreset" style="margin-left: 10px; width: calc(100% - 80px);">
                        <option value="custom">Custom</option>
                        <option value="bedroom">Bedroom (4√ó4√ó2.5m)</option>
                        <option value="living">Living Room (6√ó8√ó3m)</option>
                        <option value="studio">Studio (8√ó10√ó3m)</option>
                        <option value="medium" selected>Medium Room (8√ó6√ó3.2m)</option>
                        <option value="hall">Concert Hall (20√ó25√ó8m)</option>
                        <meta name="description" content="Arby Audio 3D  Cinematic Spatial Sound Engine   Experience living sound that adapts bounces and reacts without configuration  with advanced objectbased 714 spatial realismMade with  by Spacecode WITH 7 YEARS OF MAKINGVersionhttpsimgshieldsiobadgeversion22blueContributions WelcomehttpsimgshieldsiobadgecontributionswelcomebrightgreenPython Versionhttpsimgshieldsiobadgepython311blueBuild StatushttpsimgshieldsiobadgebuildpassingbrightgreenLast Commithttpsimgshieldsiogithublastcommitspacecontributesarbyaudio_3dStarshttpsimgshieldsiogithubstarsspacecontributesarbyaudio_3dstylesocialForkshttpsimgshieldsiogithubforksspacecontributesarbyaudio_3dstylesocialOpen Issueshttpsimgshieldsiogithubissuesspacecontributesarbyaudio_3dClosed Issueshttpsimgshieldsiogithubissuesclosedspacecontributesarbyaudio_3dDownloadshttpsimgshieldsiogithubdownloadsspacecontributesarbyaudio_3dtotalMaintenancehttpsimgshieldsiobadgemaintenanceactivebrightgreenSupported OShttpsimgshieldsiobadgeoswindows2020macOS2020LinuxlightgreyTop Languagehttpsimgshieldsiogithublanguagestopspacecontributesarbyaudio_3dRepo Sizehttpsimgshieldsiogithubreposizespacecontributesarbyaudio_3dCommitshttpsimgshieldsiogithubcommitactivitymspacecontributesarbyaudio_3dIssues Closedhttpsimgshieldsiogithubissuesprclosedspacecontributesarbyaudio_3dArby Audio Logohttpsrawgithubusercontentcomspacecontributesarbyaudio_3drefsheadsmainArby20Logo20Design20Proto11jpgArby Audio delivers cinematicgrade 3D sound with immersive 714 spatial audioEnjoy living sound that reacts in real time bringing games movies and music to life with natural reflections precise positioning and stunning binaural effects  Arby Audio vs the typical system  The typical system Maps sound objects as virtual waves with delays and reflections Provides 360 surround immersion Default quality 42kHz  24bit Adaptive spatial realism across devices Widely adopted in theaters and consumer hardware depends on system configuration  Arby AudioLiving sound that bounces adapts and reacts Not just heard but felt Smart room scaling brings audio to life  Reflections furniture occlusion immersive realismwithout any sensors cameras microphones Mind  blown Arby Audio pushes beyond traditional audio engines with realworld acoustic simulation Room geometry  reflections Distancebased and sound wave bouncing time delays Frequencydependent lowpass filtering if bounced sound wave if bounced less frequency  clipping for random high frequency audio Background noise reduction Speaker mapping to 714 layout 7 down 4 up 1 sub Binaural downmix for headphones Trajectorybased moving sound sources Furnitureenvironment scanning for realistic reflections Automatic normalization  highfrequency smoothing Highfidelity output 96kHz  32bit 4 industry standard Fully open source  customizable  Feature Breakdown Room Geometry  Reflections  Sound bounces naturally off virtual walls ceilings and objects Virtual Object Detection  Sounds interact with detected scene objects Realistic Delays  Travel  reflection delays modeled after real physics MaterialAware Filtering  Simulates absorption  air damping Speaker Mapping  True 714 Atmosstyle layout Binaural Downmix  Immersive stereo playback Background Noise Removal  Removes background noise Dynamic Trajectories  Moving sources with path realism Environment Scanning  Furnitureobjects intelligently shape reflections Clipping Protection  Autonormalization ensures stable output Room Geometry  Reflections  Sound bounces naturally off virtual walls ceilings and objects Detects Virtual Objects  Sound bounces off naturally over virtual objects detected in the scene Sound Bounces  with a delay for realism to reach the object and bounce off it DistanceBased Time Delays  Delays replicate realworld propagation for precise spatialization FrequencyDependent LowPass Filtering  Simulates material absorption and air damping StudioGrade Fidelity  96kHz  32bit audio 4 the industry standard  Who Is It For  Gamers  Game Developers  Audiophiles  Music Producers  VR  AR Developers  Film  Multimedia Editors  Educational  Research Labs  Setup  UsageClone or download the repo or download the releases the latest onebashgit clone httpsgithubcomspacecodearbyaudio_3dgitcd arbyaudio_3dOR DOWNLOAD FIELS INDUVISUALLY PYTHON OR HTML YOU CHOOSEHTMLOpen the file in a browserPythonRun the engine with your audio filebashpython PYTHONSCRIPTpy music_url httpsyourmusicurlcomfilewavOR DOWNLOAD THE FILES INDIVIDUALLY through the GitHub websitereplace with your own wav URL OR FOR WINDOWSStill requires cloning the repo or downloading files individually from the GitHub websiteRun the WOOBAT as administratorThen if it gets stuck restart itIf it is not processing the WAV try shortening the URL using tinyurlcom and try again with the updated link FOR MACOS AND LINUXor WOOsh for Linux OR MacOS file as rootsudosuFor shchmod x WOOsh  sudo WOOshThen if it gets stuck restart it If it were to be stuck on Python installation confirm Python is installed by a command and then restart WOOsh because sometimes it forgets that Python is done installing  Roadmap Google Drive integration Windows bat launcher doubleclick ready GUI frontend for nontechnical users Expanded VRAR SDK support  License  LegalBy downloading installing or using Arby Audio 3D you agree to the terms in LICENSEmdLICENSEmdThis project is for educational and ethical use only For educational and ethical testing only  unauthorized use is illegal Contributions welcome Fork the repo create a branch and submit a PR Disclaimer  Educational and Ethical Use OnlyThis project is created strictly for educational and ethical use only All product names trademarks and registered trademarks mentioned are the property of their respective ownersThis project is not affiliated with endorsed by or sponsored by any company brand or trademark holderThis service is provided on a asis basis with good faith and no obligations or warranties towards the same Not to DefameThis material is intended for informational research and educational purposes only It is not intended to disparage defame or negatively impact the reputation of any company brand or trademark holderThe authors intent is strictly educational and researchfocused Any misuse of this project or its materials is the sole responsibility of the user The author shall not be liable or responsible for such misuse as that was never the intent Independent DevelopmentArby Audio 3D is an independent opensource project While it draws inspiration from cinematicgrade audio technologies such as objectbased surround and spatial audio systems it has no official affiliation with any company brand or trademark holder Trademark NoticeAll names logos and brands mentioned in this project are the property of their respective owners References are made solely for descriptive educational and comparative purposes and even indirect references and other types of references that may cause INCIDENTAL SPECIAL CONSEQUENTIAL OR PUNITIVE DAMAGES INCLUDING WITHOUT LIMITATION regarding LOSS OF PROFITS LOSS OF DATA BUSINESS INTERRUPTION OR LOSS OF BUSINESS OPPORTUNITIES"> <meta name="keywords" content="3D Audio, Surround Sound, Spatial Engine, Arby Audio, 7.1.4, Binaural"> <meta name="description" content="3D Arby Audio Engine - Realistic 7.1.4 surround sound simulation with physical reflection modeling."> <!-- Core metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="title" content="Arby Audio 3D - Cinematic Spatial Sound Engine">
<meta name="description" content="Experience living sound that adapts, bounces, and reacts with advanced object-based 7.1.4 spatial realism. Made by Spacecode after 7 years of innovation.">
<meta name="keywords" content="3D Audio, Spatial Sound, Surround Engine, Binaural, 7.1.4, Dolby Atmos, Cinematic Audio, Python, Arby Audio, Spacecode, Space-code, Space-code">
<meta name="author" content="Spacecode">
<meta name="robots" content="index, follow">

<!-- Open Graph (for social previews) -->
<meta property="og:title" content="Arby Audio 3D - Cinematic Spatial Sound Engine">
<meta property="og:description" content="Living sound that adapts and reacts ‚Äî advanced 7.1.4 spatial realism. Experience audio that feels alive.">
<meta property="og:image" content="https://raw.githubusercontent.com/spacecontributes/arbyaudio_3d/refs/heads/main/Arby%20Logo%20Design%20Proto11.jpg">
<meta property="og:url" content="https://spacecontributes.github.io/arby-audio_3d/">
<meta property="og:type" content="website">

<!-- Twitter Card -->
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:title" content="Arby Audio 3D - Cinematic Spatial Sound Engine">
<meta name="twitter:description" content="Living sound that bounces, adapts, and reacts ‚Äî true 7.1.4 spatial realism by Spacecode.">
<meta name="twitter:image" content="https://raw.githubusercontent.com/spacecontributes/arbyaudio_3d/refs/heads/main/Arby%20Logo%20Design%20Proto11.jpg">
                    </select>
                    <div style="margin-top: 10px;"><strong>üì¶ Volume:</strong> <span id="roomVolume">153.6 m¬≥</span></div>
                </div>

                <div class="control-group">
                    <label>Room Width (m) <span class="auto-badge">Auto</span></label>
                    <div class="input-row">
                        <input type="range" id="roomWidth" min="2" max="20" step="0.1" value="8" />
                        <input type="number" id="roomWidthNum" min="2" max="20" step="0.1" value="8" />
                        <span class="value-display" id="roomWidthValue">8.0m</span>
                    </div>
                </div>

                <div class="control-group">
                    <label>Room Length (m) <span class="auto-badge">Auto</span></label>
                    <div class="input-row">
                        <input type="range" id="roomLength" min="2" max="25" step="0.1" value="6" />
                        <input type="number" id="roomLengthNum" min="2" max="25" step="0.1" value="6" />
                        <span class="value-display" id="roomLengthValue">6.0m</span>
                    </div>
                </div>

                <div class="control-group">
                    <label>Room Height (m) <span class="auto-badge">Auto</span></label>
                    <div class="input-row">
                        <input type="range" id="roomHeight" min="2" max="12" step="0.05" value="3.2" />
                        <input type="number" id="roomHeightNum" min="2" max="12" step="0.05" value="3.2" />
                        <span class="value-display" id="roomHeightValue">3.20m</span>
                    </div>
                </div>

                <div class="control-group">
                    <label>Wall Reflectivity <span class="auto-badge">Adaptive</span></label>
                    <div class="input-row">
                        <input type="range" id="wallReflectivity" min="0.1" max="0.95" step="0.01" value="0.7" />
                        <input type="number" id="wallReflectivityNum" min="0.1" max="0.95" step="0.01" value="0.7" />
                        <span class="value-display" id="wallReflectivityValue">0.70</span>
                    </div>
                </div>

                <div class="control-group">
                    <label>Air Absorption <span class="auto-badge">Auto</span></label>
                    <div class="input-row">
                        <input type="range" id="airAbsorption" min="0.001" max="0.05" step="0.001" value="0.01" />
                        <input type="number" id="airAbsorptionNum" min="0.001" max="0.05" step="0.001" value="0.01" />
                        <span class="value-display" id="airAbsorptionValue">0.010</span>
                    </div>
                </div>

                <div class="checkbox-group">
                    <input type="checkbox" id="enableAdaptiveGain" checked />
                    <label for="enableAdaptiveGain">‚ö° Adaptive Anti-Clipping</label>
                </div>

                <div class="checkbox-group">
                    <input type="checkbox" id="enableLinearScaling" checked />
                    <label for="enableLinearScaling">üìê Linear Scaling (k, p, Œ±)</label>
                </div>

                <div class="checkbox-group">
                    <input type="checkbox" id="enableAutoRoomScale" checked />
                    <label for="enableAutoRoomScale">üéØ Auto Room Scale</label>
                </div>
            </div>
        </div>

        <div class="panel">
            <h2>üéõÔ∏è Processing</h2>
               <div>
    <button id="processBtn" disabled>‚ö° Process Audio</button>
    <button id="playBtn" disabled>‚ñ∂Ô∏è Play</button>
    <button id="stopBtn" disabled>‚èπÔ∏è Stop</button>
    <button id="downloadBtn" disabled>üíæ Download Audio</button>
    <button id="createVideoBtn" disabled>üé¨ Create Video</button>
</div>
          
            <div class="progress"><div class="progress-bar" id="progressBar"></div></div>
            <div class="status">
                <div class="status-item"><span>Status:</span><span id="processingStatus">Ready</span></div>
                <div class="status-item"><span>Time:</span><span id="processingTime">-</span></div>
                <div class="status-item"><span>Size:</span><span id="outputSize">-</span></div>
            </div>
            <div class="success" id="autoScaleInfo" style="display: none;">
                <div id="autoScaleDetails"></div>
            </div>
            <div class="visualizer"><canvas id="visualizerCanvas"></canvas></div>
        </div>

        <div class="panel">
            <h2>üîä 7.1.4 Layout</h2>
            <div class="speaker-map">
                <div class="speaker">L<br>Front Left</div>
                <div class="speaker">R<br>Front Right</div>
                <div class="speaker">C<br>Center</div>
                <div class="speaker">LFE<br>Sub</div>
                <div class="speaker">SL<br>Side L</div>
                <div class="speaker">SR<br>Side R</div>
                <div class="speaker">BL<br>Back L</div>
                <div class="speaker">BR<br>Back R</div>
                <div class="speaker">TFL<br>Top FL</div>
                <div class="speaker">TFR<br>Top FR</div>
                <div class="speaker">TBL<br>Top BL</div>
                <div class="speaker">TBR<br>Top BR</div>
            </div>
        </div>
    </div>

    <script>
// Security configuration
const SECURITY_CONFIG = {
    allowedMimeTypes: new Set(['audio/wav', 'audio/mpeg', 'audio/mp3', 'audio/x-m4a', 'audio/flac', 'audio/ogg', 'video/mp4', 'video/webm', 'video/avi']),
    allowedExtensions: new Set(['.wav', '.mp3', '.flac', '.ogg', '.m4a', '.mp4', '.webm', '.avi']),
    maxSampleRate: 192000,
    maxChannels: 8,
    rateLimitWindow: 60000,
    maxProcessingPerWindow: 5,
    ranges: {
        roomWidth: { min: 2, max: 20, step: 0.1 },
        roomLength: { min: 2, max: 25, step: 0.1 },
        roomHeight: { min: 2, max: 12, step: 0.05 },
        wallReflectivity: { min: 0.1, max: 0.95, step: 0.01 },
        airAbsorption: { min: 0.001, max: 0.05, step: 0.001 }
    }
};

// Rate limiter
const rateLimiter = {
    attempts: [],
    canProcess() {
        const now = Date.now();
        this.attempts = this.attempts.filter(t => now - t < SECURITY_CONFIG.rateLimitWindow);
        if (this.attempts.length >= SECURITY_CONFIG.maxProcessingPerWindow) {
            const oldestAttempt = Math.min(...this.attempts);
            const waitTime = Math.ceil((SECURITY_CONFIG.rateLimitWindow - (now - oldestAttempt)) / 1000);
            return { allowed: false, waitTime };
        }
        return { allowed: true };
    },
    recordAttempt() {
        this.attempts.push(Date.now());
    }
};

// Numeric input validation
function validateNumericInput(value, paramName) {
    const range = SECURITY_CONFIG.ranges[paramName];
    if (!range) return parseFloat(value);
    const num = parseFloat(value);
    if (isNaN(num) || num < range.min || num > range.max) {
        throw new Error(`Invalid ${paramName}`);
    }
    return Math.round(num / range.step) * range.step;
}

// ArbyAudioEngine class
class ArbyAudioEngine {
    constructor() {
        this.audioContext = null;
        this.sourceBuffer = null;
        this.processedBuffer = null;
        this.isPlaying = false;
        this.sourceNode = null;
        
        this.speakerPositions = [
            { name: 'L', az: -30, el: 0 },
            { name: 'R', az: 30, el: 0 },
            { name: 'C', az: 0, el: 0 },
            { name: 'LFE', az: 0, el: -90 },
            { name: 'SL', az: -110, el: 0 },
            { name: 'SR', az: 110, el: 0 },
            { name: 'BL', az: -150, el: 0 },
            { name: 'BR', az: 150, el: 0 },
            { name: 'TFL', az: -30, el: 45 },
            { name: 'TFR', az: 30, el: 45 },
            { name: 'TBL', az: -150, el: 45 },
            { name: 'TBR', az: 150, el: 45 }
        ];
    }

    async initialize() {
        this.audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 96000 });
    }

    async loadAudioFile(file) {
        const arrayBuffer = await file.arrayBuffer();
        const audioBuffer = await this.audioContext.decodeAudioData(arrayBuffer);
        this.sourceBuffer = audioBuffer;
        return audioBuffer;
    }

    getMonoData(buffer) {
        const channels = buffer.numberOfChannels;
        const length = buffer.length;
        const monoData = new Float32Array(length);
        
        for (let ch = 0; ch < channels; ch++) {
            const channelData = buffer.getChannelData(ch);
            for (let i = 0; i < length; i++) {
                monoData[i] += channelData[i] / channels;
            }
        }
        return monoData;
    }

    createLowPassFilter(sampleRate, cutoffFreq) {
        const rc = 1.0 / (2.0 * Math.PI * cutoffFreq);
        const dt = 1.0 / sampleRate;
        const alpha = dt / (rc + dt);
        return {
            alpha,
            process(input, prevOutput) {
                return prevOutput + alpha * (input - prevOutput);
            }
        };
    }

    async upsample(data, fromRate, toRate) {
        if (fromRate === toRate) return data;
        const ratio = toRate / fromRate;
        const newLength = Math.floor(data.length * ratio);
        const upsampled = new Float32Array(newLength);
        for (let i = 0; i < newLength; i++) {
            const srcIndex = i / ratio;
            const srcIndexFloor = Math.floor(srcIndex);
            const srcIndexCeil = Math.min(srcIndexFloor + 1, data.length - 1);
            const frac = srcIndex - srcIndexFloor;
            upsampled[i] = data[srcIndexFloor] * (1 - frac) + data[srcIndexCeil] * frac;
        }
        return upsampled;
    }

    async process(config, onProgress) {
        const startTime = performance.now();
        const validatedConfig = {
            wallReflectivity: validateNumericInput(config.wallReflectivity, 'wallReflectivity'),
            roomWidth: validateNumericInput(config.roomWidth, 'roomWidth'),
            roomLength: validateNumericInput(config.roomLength, 'roomLength'),
            roomHeight: validateNumericInput(config.roomHeight, 'roomHeight'),
            airAbsorption: validateNumericInput(config.airAbsorption, 'airAbsorption'),
            enableAdaptiveGain: !!config.enableAdaptiveGain,
            enableLinearScaling: !!config.enableLinearScaling,
            enableAutoRoomScale: !!config.enableAutoRoomScale
        };
        
        const sourceSampleRate = this.sourceBuffer.sampleRate;
        const targetSampleRate = 96000;
        const monoData = this.getMonoData(this.sourceBuffer);
        
        let rms = 0;
        for (let i = 0; i < monoData.length; i++) {
            rms += monoData[i] * monoData[i];
        }
        rms = Math.sqrt(rms / monoData.length);
        
        if (validatedConfig.enableAutoRoomScale && rms > 0.1) {
            const scaleFactor = 1 + (rms - 0.1) * 2;
            validatedConfig.roomWidth = Math.min(validatedConfig.roomWidth * scaleFactor, 20);
            validatedConfig.roomLength = Math.min(validatedConfig.roomLength * scaleFactor, 25);
            validatedConfig.roomHeight = Math.min(validatedConfig.roomHeight * scaleFactor, 12);
        }
        
        const upsampled = await this.upsample(monoData, sourceSampleRate, targetSampleRate);
        onProgress(20);
        
        const processed = await this.processSpatialReflections(upsampled, targetSampleRate, validatedConfig, rms, onProgress);
        onProgress(100);
        
        return {
            buffer: processed,
            processingTime: ((performance.now() - startTime) / 1000).toFixed(2),
            autoScaleInfo: this.getAutoScaleInfo(validatedConfig, rms)
        };
    }

    getAutoScaleInfo(config, rms) {
        const avgRoomSize = (config.roomWidth + config.roomLength + config.roomHeight) / 3;
        const maxReflectionDist = Math.sqrt(config.roomWidth ** 2 + config.roomLength ** 2 + config.roomHeight ** 2);
        const maxDelay = (maxReflectionDist / 343 * 1000).toFixed(1);
        
        let k, p;
        if (config.enableLinearScaling) {
            k = 0.3 + (avgRoomSize / 15) * 0.4;
            p = 1.0 + (avgRoomSize / 15) * 0.5;
        } else {
            k = 0.5;
            p = 1.2;
        }
        
        const volume = config.roomWidth * config.roomLength * config.roomHeight;
        return {
            k: k.toFixed(3),
            p: p.toFixed(3),
            maxReflectionDelay: maxDelay + 'ms',
            airAbsorptionRate: (config.airAbsorption * 100).toFixed(2) + '%/m',
            wallReflectivity: (config.wallReflectivity * 100).toFixed(0) + '%',
            volume: volume.toFixed(1) + ' m¬≥',
            dimensions: `${config.roomWidth.toFixed(1)}√ó${config.roomLength.toFixed(1)}√ó${config.roomHeight.toFixed(2)}m`,
            scalingMode: config.enableLinearScaling ? 'Linear Auto' : 'Fixed',
            soundPressureLevel: (rms * 100).toFixed(1) + '% RMS',
            autoRoomScaled: config.enableAutoRoomScale
        };
    }

    async processSpatialReflections(audioData, sampleRate, config, rms, onProgress) {
        const numChannels = 12;
        const numSamples = audioData.length;
        const output = Array.from({ length: numChannels }, () => new Float32Array(numSamples));
        
        const c = 343;
        const fs = sampleRate;
        const avgRoomSize = (config.roomWidth + config.roomLength + config.roomHeight) / 3;
        
        let k_base, p_exponent;
        if (config.enableLinearScaling) {
            k_base = 0.3 + (avgRoomSize / 15) * 0.4;
            p_exponent = 1.0 + (avgRoomSize / 15) * 0.5;
        } else {
            k_base = 0.5;
            p_exponent = 1.2;
        }
        
        let alpha = config.airAbsorption;
        if (config.enableAutoRoomScale) {
            alpha *= (1 + rms * 0.5);
        }
        
        const walls = [
            { name: 'front', normal: [0, 0, 1], pos: [0, 0, config.roomLength/2] },
            { name: 'back', normal: [0, 0, -1], pos: [0, 0, -config.roomLength/2] },
            { name: 'left', normal: [1, 0, 0], pos: [-config.roomWidth/2, 0, 0] },
            { name: 'right', normal: [-1, 0, 0], pos: [config.roomWidth/2, 0, 0] },
            { name: 'ceiling', normal: [0, -1, 0], pos: [0, config.roomHeight/2, 0] },
            { name: 'floor', normal: [0, 1, 0], pos: [0, -config.roomHeight/2, 0] }
        ];
        
        const listenerPos = [0, 0, 0];
        let currentReflGain = config.wallReflectivity;
        
        if (config.enableAutoRoomScale) {
            const softnessEffect = (1 - config.wallReflectivity) * rms;
            currentReflGain *= (1 - softnessEffect * 0.3);
        }
        
        const chunkSize = 4096;
        const numChunks = Math.ceil(numSamples / chunkSize);
        const filterStates = walls.map(() => Array(numChannels).fill(0));
        
        for (let chunk = 0; chunk < numChunks; chunk++) {
            const start = chunk * chunkSize;
            const end = Math.min(start + chunkSize, numSamples);
            
            const sourcePos = [2, 0, 0];
            const directDist = Math.sqrt(sourcePos.reduce((sum, v) => sum + v*v, 0));
            const directDelay = Math.floor(directDist / c * fs);
            const directGain = 1 / (1 + k_base * Math.pow(directDist, p_exponent));
            const directGains = this.calculateSpeakerGains(0, 0);
            
            for (let i = start; i < end; i++) {
                const srcIdx = i - directDelay;
                if (srcIdx >= 0 && srcIdx < audioData.length) {
                    const sample = audioData[srcIdx] * directGain;
                    for (let ch = 0; ch < numChannels; ch++) {
                        output[ch][i] += sample * directGains[ch];
                    }
                }
            }
            
            walls.forEach((wall, wallIdx) => {
                const reflectedPos = this.reflectPoint(sourcePos, wall.pos, wall.normal);
                const reflectionPath = this.vectorSubtract(reflectedPos, listenerPos);
                const reflectionDist = Math.sqrt(reflectionPath.reduce((sum, v) => sum + v*v, 0));
                const reflectionAz = Math.atan2(reflectionPath[0], reflectionPath[2]) * 180 / Math.PI;
                const reflectionEl = Math.asin(reflectionPath[1] / reflectionDist) * 180 / Math.PI;
                const reflectionDelay = Math.floor(reflectionDist / c * fs);
                const distAttenuation = 1 / (1 + k_base * Math.pow(reflectionDist, p_exponent));
                const airAbsorption = Math.exp(-alpha * reflectionDist);
                const Rw = currentReflGain * distAttenuation * airAbsorption;
                
                const maxRoomDist = Math.sqrt(config.roomWidth ** 2 + config.roomLength ** 2 + config.roomHeight ** 2);
                const normDist = Math.min(reflectionDist / maxRoomDist, 1);
                const cutoffFreq = fs * (0.45 - 0.35 * normDist);
                const lpFilter = this.createLowPassFilter(fs, cutoffFreq);
                const reflectionGains = this.calculateSpeakerGains(reflectionAz, reflectionEl);
                
                for (let i = start; i < end; i++) {
                    const srcIdx = i - reflectionDelay;
                    if (srcIdx >= 0 && srcIdx < audioData.length) {
                        const sample = audioData[srcIdx];
                        for (let ch = 0; ch < numChannels; ch++) {
                            const filteredSample = lpFilter.process(sample, filterStates[wallIdx][ch]);
                            filterStates[wallIdx][ch] = filteredSample;
                            output[ch][i] += filteredSample * Rw * reflectionGains[ch];
                        }
                    }
                }
            });
            
            if (config.enableAdaptiveGain) {
                let chunkPeak = 0;
                for (let ch = 0; ch < numChannels; ch++) {
                    for (let i = start; i < end; i++) {
                        chunkPeak = Math.max(chunkPeak, Math.abs(output[ch][i]));
                    }
                }
                if (chunkPeak > 0.8) {
                    currentReflGain *= 0.95;
                } else if (chunkPeak < 0.5 && currentReflGain < config.wallReflectivity) {
                    currentReflGain *= 1.02;
                }
            }
            
            if (chunk % 10 === 0) {
                onProgress(20 + Math.floor((chunk / numChunks) * 80));
            }
        }
        
        let maxSample = 0;
        for (let ch = 0; ch < numChannels; ch++) {
            for (let i = 0; i < numSamples; i++) {
                maxSample = Math.max(maxSample, Math.abs(output[ch][i]));
            }
        }
        
        if (maxSample > 0.95) {
            const normFactor = 0.95 / maxSample;
            for (let ch = 0; ch < numChannels; ch++) {
                for (let i = 0; i < numSamples; i++) {
                    output[ch][i] *= normFactor;
                }
            }
        }
        
        const buffer = this.audioContext.createBuffer(numChannels, numSamples, sampleRate);
        for (let ch = 0; ch < numChannels; ch++) {
            buffer.copyToChannel(output[ch], ch);
        }
        
        this.processedBuffer = buffer;
        return buffer;
    }

    reflectPoint(point, planePoint, planeNormal) {
        const d = this.vectorDot(this.vectorSubtract(point, planePoint), planeNormal);
        return [
            point[0] - 2 * d * planeNormal[0],
            point[1] - 2 * d * planeNormal[1],
            point[2] - 2 * d * planeNormal[2]
        ];
    }

    vectorSubtract(a, b) {
        return [a[0] - b[0], a[1] - b[1], a[2] - b[2]];
    }

    vectorDot(a, b) {
        return a[0] * b[0] + a[1] * b[1] + a[2] * b[2];
    }

    calculateSpeakerGains(azimuth, elevation) {
        const gains = new Float32Array(12);
        for (let i = 0; i < this.speakerPositions.length; i++) {
            const sp = this.speakerPositions[i];
            const azDiff = Math.abs(azimuth - sp.az);
            const elDiff = Math.abs(elevation - sp.el);
            const angularDist = Math.sqrt(azDiff * azDiff + elDiff * elDiff);
            gains[i] = 1 / (1 + angularDist / 45);
        }
        const sumGains = gains.reduce((sum, g) => sum + g * g, 0);
        const normFactor = sumGains > 0 ? 1 / Math.sqrt(sumGains) : 0;
        for (let i = 0; i < gains.length; i++) {
            gains[i] *= normFactor;
        }
        return gains;
    }

    async play() {
        if (!this.processedBuffer || this.isPlaying) return;
        this.sourceNode = this.audioContext.createBufferSource();
        this.sourceNode.buffer = this.processedBuffer;
        this.sourceNode.connect(this.audioContext.destination);
        this.sourceNode.onended = () => {
            this.isPlaying = false;
            document.getElementById('playBtn').textContent = '‚ñ∂Ô∏è Play';
            document.getElementById('stopBtn').disabled = true;
        };
        this.sourceNode.start();
        this.isPlaying = true;
    }

    stop() {
        if (this.sourceNode && this.isPlaying) {
            this.sourceNode.stop();
            this.isPlaying = false;
        }
    }

    exportWAV() {
        if (!this.processedBuffer) return null;
        const numChannels = this.processedBuffer.numberOfChannels;
        const length = this.processedBuffer.length;
        const sampleRate = this.processedBuffer.sampleRate;
        const buffer = new ArrayBuffer(44 + length * numChannels * 4);
        const view = new DataView(buffer);
        
        this.writeString(view, 0, 'RIFF');
        view.setUint32(4, 36 + length * numChannels * 4, true);
        this.writeString(view, 8, 'WAVE');
        this.writeString(view, 12, 'fmt ');
        view.setUint32(16, 16, true);
        view.setUint16(20, 3, true);
        view.setUint16(22, numChannels, true);
        view.setUint32(24, sampleRate, true);
        view.setUint32(28, sampleRate * numChannels * 4, true);
        view.setUint16(32, numChannels * 4, true);
        view.setUint16(34, 32, true);
        this.writeString(view, 36, 'data');
        view.setUint32(40, length * numChannels * 4, true);
        
        let offset = 44;
        for (let i = 0; i < length; i++) {
            for (let ch = 0; ch < numChannels; ch++) {
                view.setFloat32(offset, this.processedBuffer.getChannelData(ch)[i], true);
                offset += 4;
            }
        }
        return new Blob([buffer], { type: 'audio/wav' });
    }

    writeString(view, offset, string) {
        for (let i = 0; i < string.length; i++) {
            view.setUint8(offset + i, string.charCodeAt(i));
        }
    }
}

// ============================================
// Advanced Multi-Object Tracking System
// ============================================
class TrackedObject {
    constructor(bbox, trackId) {
        this.bbox = bbox; // {x, y, w, h}
        this.trackId = trackId;
        this.positionHistory = []; // Last 30 frames
        this.velocity = {x: 0, y: 0};
        this.framesTracked = 0;
        this.isActive = true;
        this.audioCorrelation = 0.0;
        this.depthEstimate = 1.0; // meters
    }
    
    update(bbox) {
        const cx = bbox.x + bbox.w / 2;
        const cy = bbox.y + bbox.h / 2;
        
        if (this.positionHistory.length > 0) {
            const last = this.positionHistory[this.positionHistory.length - 1];
            this.velocity.x = cx - last.cx;
            this.velocity.y = cy - last.cy;
        }
        
        this.positionHistory.push({cx, cy, w: bbox.w, h: bbox.h});
        if (this.positionHistory.length > 30) {
            this.positionHistory.shift();
        }
        
        this.bbox = bbox;
        this.framesTracked++;
        this.isActive = true;
        
        // Depth from bounding box size (perspective scale)
        const boxScale = Math.sqrt(bbox.w * bbox.h);
        this.depthEstimate = Math.max(0.5, 5.0 / (boxScale / 100.0 + 0.1));
        
        // Depth from motion parallax
        if (this.positionHistory.length >= 5) {
            const recentMotion = Math.sqrt(this.velocity.x ** 2 + this.velocity.y ** 2);
            const parallaxDepth = Math.max(0.5, 3.0 / (recentMotion + 0.1));
            // Weighted fusion
            this.depthEstimate = 0.6 * this.depthEstimate + 0.4 * parallaxDepth;
        }
    }
}

class MultiObjectTracker {
    constructor(maxObjects = 16) {
        this.maxObjects = maxObjects;
        this.trackedObjects = [];
        this.nextId = 0;
        this.maxDistanceThreshold = 50; // pixels
    }
    
    update(detections) {
        // Mark all as inactive
        this.trackedObjects.forEach(obj => obj.isActive = false);
        
        const usedDetections = new Set();
        
        // Data association: match detections to existing tracks
        for (const obj of this.trackedObjects) {
            if (obj.positionHistory.length === 0) continue;
            
            const last = obj.positionHistory[obj.positionHistory.length - 1];
            const predictedX = last.cx + obj.velocity.x;
            const predictedY = last.cy + obj.velocity.y;
            
            let bestMatchIdx = -1;
            let bestDistance = this.maxDistanceThreshold;
            
            for (let i = 0; i < detections.length; i++) {
                if (usedDetections.has(i)) continue;
                
                const bbox = detections[i];
                const cx = bbox.x + bbox.w / 2;
                const cy = bbox.y + bbox.h / 2;
                const dist = Math.sqrt((predictedX - cx) ** 2 + (predictedY - cy) ** 2);
                
                if (dist < bestDistance) {
                    bestDistance = dist;
                    bestMatchIdx = i;
                }
            }
            
            if (bestMatchIdx >= 0) {
                obj.update(detections[bestMatchIdx]);
                usedDetections.add(bestMatchIdx);
            }
        }
        
        // Create new tracks for unmatched detections
        for (let i = 0; i < detections.length; i++) {
            if (!usedDetections.has(i) && this.trackedObjects.length < this.maxObjects) {
                const newObj = new TrackedObject(detections[i], this.nextId++);
                newObj.update(detections[i]);
                this.trackedObjects.push(newObj);
            }
        }
        
        // Prune stale tracks (inactive for >10 frames)
        this.trackedObjects = this.trackedObjects.filter(
            obj => obj.isActive || obj.framesTracked < 10
        );
        
        return this.trackedObjects;
    }
}

// Audio-motion correlation system
const audioEnergyHistory = [];
const motionEnergyHistory = [];
const CORRELATION_WINDOW = 5;

function calculateAudioMotionCorrelation(audioEnergy, motionEnergy) {
    audioEnergyHistory.push(audioEnergy);
    motionEnergyHistory.push(motionEnergy);
    
    if (audioEnergyHistory.length > 30) {
        audioEnergyHistory.shift();
        motionEnergyHistory.shift();
    }
    
    if (audioEnergyHistory.length < 10) return 0.0;
    
    const recent = 10;
    const audioArr = audioEnergyHistory.slice(-recent);
    const motionArr = motionEnergyHistory.slice(-recent);
    
    // Zero-lag correlation
    const audioMean = audioArr.reduce((a, b) => a + b) / recent;
    const motionMean = motionArr.reduce((a, b) => a + b) / recent;
    
    let numerator = 0;
    let audioDenom = 0;
    let motionDenom = 0;
    
    for (let i = 0; i < recent; i++) {
        const audioDiff = audioArr[i] - audioMean;
        const motionDiff = motionArr[i] - motionMean;
        numerator += audioDiff * motionDiff;
        audioDenom += audioDiff ** 2;
        motionDenom += motionDiff ** 2;
    }
    
    const corr = numerator / Math.sqrt(audioDenom * motionDenom + 1e-9);
    return Math.abs(isNaN(corr) ? 0 : corr);
function detectMotionBlobs(currentFrame, prevFrame, width, height) {
    const detections = [];
    const threshold = 15; // Lower threshold for better sensitivity
    const gridSize = 20;  // Larger grid for better object grouping
    const cols = Math.floor(width / gridSize);
    const rows = Math.floor(height / gridSize);
    
    // First pass: detect motion in grid cells
    const motionGrid = [];
    for (let gy = 0; gy < rows; gy++) {
        motionGrid[gy] = [];
        for (let gx = 0; gx < cols; gx++) {
            let diff = 0;
            let count = 0;
            
            for (let dy = 0; dy < gridSize; dy++) {
                for (let dx = 0; dx < gridSize; dx++) {
                    const x = gx * gridSize + dx;
                    const y = gy * gridSize + dy;
                    if (x >= width || y >= height) continue;
                    
                    const idx = (y * width + x) * 4;
                    
                    const currGray = (currentFrame.data[idx] + 
                                     currentFrame.data[idx + 1] + 
                                     currentFrame.data[idx + 2]) / 3;
                    const prevGray = (prevFrame.data[idx] + 
                                     prevFrame.data[idx + 1] + 
                                     prevFrame.data[idx + 2]) / 3;
                    
                    diff += Math.abs(currGray - prevGray);
                    count++;
                }
            }
            
            motionGrid[gy][gx] = (diff / count) > threshold ? 1 : 0;
        }
    }
    
    // Second pass: group connected components
    const visited = Array(rows).fill(0).map(() => Array(cols).fill(false));
    
    function floodFill(startY, startX) {
        const stack = [{y: startY, x: startX}];
        let minX = startX, maxX = startX;
        let minY = startY, maxY = startY;
        let cellCount = 0;
        
        while (stack.length > 0) {
            const {y, x} = stack.pop();
            
            if (y < 0 || y >= rows || x < 0 || x >= cols) continue;
            if (visited[y][x] || motionGrid[y][x] === 0) continue;
            
            visited[y][x] = true;
            cellCount++;
            
            minX = Math.min(minX, x);
            maxX = Math.max(maxX, x);
            minY = Math.min(minY, y);
            maxY = Math.max(maxY, y);
            
            // 8-connected neighborhood
            stack.push({y: y-1, x: x-1}, {y: y-1, x: x}, {y: y-1, x: x+1});
            stack.push({y: y, x: x-1}, {y: y, x: x+1});
            stack.push({y: y+1, x: x-1}, {y: y+1, x: x}, {y: y+1, x: x+1});
        }
        
        // Minimum blob size (at least 2x2 grid cells)
        if (cellCount >= 4) {
            return {
                x: minX * gridSize,
                y: minY * gridSize,
                w: (maxX - minX + 1) * gridSize,
                h: (maxY - minY + 1) * gridSize
            };
        }
        return null;
    }
    
    // Find all connected components
    for (let gy = 0; gy < rows; gy++) {
        for (let gx = 0; gx < cols; gx++) {
            if (motionGrid[gy][gx] === 1 && !visited[gy][gx]) {
                const blob = floodFill(gy, gx);
                if (blob) {
                    detections.push(blob);
                }
            }
        }
    }
    
    return detections;
}

const engine = new ArbyAudioEngine();
        
const engine = new ArbyAudioEngine();

document.addEventListener('DOMContentLoaded', async () => {
    await engine.initialize();

    const uploadZone = document.getElementById('uploadZone');
    const fileInput = document.getElementById('fileInput');
    const videoUpload = document.getElementById('videoUpload');
    const videoUploadZone = document.getElementById('videoUploadZone');
    const videoPreview = document.getElementById('videoPreview');
    const createVideoBtn = document.getElementById('createVideoBtn');
    const canvas = document.getElementById('canvas');
    const progressBar = document.getElementById('progressBar');
    const progressBarFill = document.getElementById('progressBarFill');
    let videoFile, audioFile, mediaRecorder, recordedChunks = [];

    if (!videoUploadZone) {
        console.error('Element with id="videoUploadZone" not found in the DOM');
        return;
    }

    uploadZone.onclick = () => fileInput.click();
    videoUploadZone.onclick = () => videoUpload.click();

    fileInput.addEventListener('change', async (e) => {
        audioFile = e.target.files[0];
        if (!audioFile) return;
        try {
            const buffer = await engine.loadAudioFile(audioFile);
            document.getElementById('fileInfo').style.display = 'block';
            document.getElementById('fileName').textContent = audioFile.name;
            document.getElementById('fileDuration').textContent = buffer.duration.toFixed(2) + 's';
            document.getElementById('fileSampleRate').textContent = buffer.sampleRate + ' Hz';
            document.getElementById('fileChannels').textContent = buffer.numberOfChannels;
            document.getElementById('processBtn').disabled = false;
            checkFiles();
        } catch (error) {
            alert('Error: ' + error.message);
        }
    });

    videoUpload.addEventListener('change', (event) => {
        videoFile = event.target.files[0];
        if (videoFile) {
            const videoURL = URL.createObjectURL(videoFile);
            videoPreview.src = videoURL;
            videoPreview.style.display = 'block';
            checkFiles();
        }
    });

    function checkFiles() {
        if (audioFile) {
            document.getElementById('processBtn').disabled = false;
            document.getElementById('downloadBtn').disabled = false;
        }
        if (videoFile && audioFile) {
            createVideoBtn.disabled = false;
        }
    }

    document.getElementById('processBtn').onclick = async () => {
        const check = rateLimiter.canProcess();
        if (!check.allowed) {
            document.getElementById('rateLimitText').textContent = `Wait ${check.waitTime}s`;
            document.getElementById('rateLimitInfo').style.display = 'block';
            return;
        }
        rateLimiter.recordAttempt();

        const config = {
            roomWidth: parseFloat(document.getElementById('roomWidth').value),
            roomLength: parseFloat(document.getElementById('roomLength').value),
            roomHeight: parseFloat(document.getElementById('roomHeight').value),
            wallReflectivity: parseFloat(document.getElementById('wallReflectivity').value),
            airAbsorption: parseFloat(document.getElementById('airAbsorption').value),
            enableAdaptiveGain: document.getElementById('enableAdaptiveGain').checked,
            enableLinearScaling: document.getElementById('enableLinearScaling').checked,
            enableAutoRoomScale: document.getElementById('enableAutoRoomScale').checked
        };

        document.getElementById('processBtn').disabled = true;
        document.getElementById('processingStatus').textContent = 'Processing...';

        try {
            const result = await engine.process(config, (p) => {
                document.getElementById('progressBar').style.width = p + '%';
            });

            document.getElementById('processingTime').textContent = result.processingTime + 's';
            document.getElementById('outputSize').textContent = '5 MB';
            document.getElementById('autoScaleInfo').style.display = 'block';
            document.getElementById('autoScaleDetails').innerHTML = `
                <strong>Room:</strong> ${result.autoScaleInfo.dimensions}<br>
                <strong>Volume:</strong> ${result.autoScaleInfo.volume}
            `;
            document.getElementById('playBtn').disabled = false;
            document.getElementById('downloadBtn').disabled = false;
            document.getElementById('processingStatus').textContent = 'Complete!';
        } catch (error) {
            alert('Error: ' + error.message);
        } finally {
            document.getElementById('processBtn').disabled = false;
        }
    };

    document.getElementById('playBtn').onclick = () => {
        engine.play();
        document.getElementById('playBtn').textContent = '‚è∏Ô∏è Playing...';
        document.getElementById('stopBtn').disabled = false;
    };

    document.getElementById('stopBtn').onclick = () => {
        engine.stop();
        if (mediaRecorder && mediaRecorder.state === 'recording') {
            mediaRecorder.stop();
        }
        document.getElementById('playBtn').textContent = '‚ñ∂Ô∏è Play';
        document.getElementById('stopBtn').disabled = true;
    };

    document.getElementById('downloadBtn').onclick = () => {
        const blob = engine.exportWAV();
        if (blob) {
            const url = URL.createObjectURL(blob);
            const downloadLink = document.createElement('a');
            downloadLink.href = url;
            downloadLink.download = 'processed-audio.wav';
            downloadLink.textContent = 'Download Processed Audio';
            document.body.appendChild(downloadLink);
            downloadLink.click();
            document.body.removeChild(downloadLink);
        }
    };

 createVideoBtn.addEventListener('click', () => {
        if (!engine.processedBuffer) {
            alert('Please process audio first.');
            return;
        }
        createVideoBtn.disabled = true;
        progressBar.style.display = 'block';
        recordedChunks = [];

        canvas.width = videoPreview.videoWidth;
        canvas.height = videoPreview.videoHeight;
        const context = canvas.getContext('2d');
        
        // Initialize tracker and CV processing
        const tracker = new MultiObjectTracker(16);
        const cvCanvas = document.createElement('canvas');
        cvCanvas.width = 320;
        cvCanvas.height = 240;
        const cvCtx = cvCanvas.getContext('2d');
        let prevFrameData = null;
        let trackingStats = {maxObjects: 0, totalFrames: 0};
        
        videoPreview.play();

        function drawFrame() {
            if (!videoPreview.paused && !videoPreview.ended) {
                // Draw full-res video
                context.drawImage(videoPreview, 0, 0, canvas.width, canvas.height);
                
                // CV processing on downsampled frame
                cvCtx.drawImage(videoPreview, 0, 0, cvCanvas.width, cvCanvas.height);
                const currentFrameData = cvCtx.getImageData(0, 0, cvCanvas.width, cvCanvas.height);
                
               if (prevFrameData) {
    const detections = detectMotionBlobs(
        currentFrameData, 
        prevFrameData, 
        cvCanvas.width, 
        cvCanvas.height
    );
    
    const trackedObjects = tracker.update(detections);
    trackingStats.maxObjects = Math.max(trackingStats.maxObjects, trackedObjects.length);
    trackingStats.totalFrames++;
    
    // ‚úÖ SPATIAL AUDIO MAPPING (MANDATORY)
    if (trackedObjects.length > 0 && engine.processedBuffer) {
        const roomConfig = {
            x: parseFloat(document.getElementById('roomWidth').value),
            y: parseFloat(document.getElementById('roomLength').value),
            z: parseFloat(document.getElementById('roomHeight').value)
        };
        
        trackedObjects.forEach(obj => {
            if (obj.positionHistory.length > 0) {
                const {cx, cy} = obj.positionHistory[obj.positionHistory.length - 1];
                
                const normX = (cx / cvCanvas.width) * 2 - 1;
                const normY = (cy / cvCanvas.height) * 2 - 1;
                
                const azimuth = normX * 90;
                const elevation = -normY * 45;
                
                const posX = normX * roomConfig.x * 0.5 * obj.depthEstimate;
                const posY = normY * roomConfig.y * 0.5 * obj.depthEstimate;
                const posZ = 0.15 + (obj.depthEstimate - 1.0) * 0.3;
                
                obj.spatialPosition = {x: posX, y: posY, z: posZ};
                obj.azimuth = azimuth;
                obj.elevation = elevation;
            }
        });
    }
    
    // ‚úÖ OPTIONAL: LIVE STATS (FIX THE TYPO!)
    if (document.getElementById('cvStats')) {
        const avgDepth = trackedObjects.reduce((sum, obj) => sum + obj.depthEstimate, 0) / (trackedObjects.length || 1);
        const audioEnergy = 0.5;
        const motionEnergy = detections.length / 100.0;
        const correlation = calculateAudioMotionCorrelation(audioEnergy, motionEnergy);
        
        document.getElementById('cvStats').style.display = 'block';
        document.getElementById('trackedCount').textContent = trackedObjects.length;
        document.getElementById('cvFrames').textContent = trackingStats.totalFrames;
        document.getElementById('audioCorr').textContent = correlation.toFixed(2);
        document.getElementById('avgDepth').textContent = avgDepth.toFixed(2) + 'm';
    }
    
    // ‚ùå NO BOUNDING BOX DRAWING (YOU SKIPPED THIS - CORRECT!)
}

prevFrameData = currentFrameData;
                    
                    
                    const trackedObjects = tracker.update(detections);
                    trackingStats.maxObjects = Math.max(trackingStats.maxObjects, trackedObjects.length);
                    trackingStats.totalFrames++;
                    
                    // Optional: Draw tracking boxes on main canvas
                    const scaleX = canvas.width / cvCanvas.width;
                    const scaleY = canvas.height / cvCanvas.height;
                    context.strokeStyle = '#00ff00';
                    context.lineWidth = 2;
                    
                    trackedObjects.forEach(obj => {
                        if (obj.positionHistory.length > 0) {
                            const {cx, cy, w, h} = obj.positionHistory[obj.positionHistory.length - 1];
                            context.strokeRect(
                                (cx - w/2) * scaleX,
                                (cy - h/2) * scaleY,
                                w * scaleX,
                                h * scaleY
                            );
                            
                            // Draw object ID
                            context.fillStyle = '#00ff00';
                            context.font = '12px monospace';
                            context.fillText(
                                `ID:${obj.trackId} D:${obj.depthEstimate.toFixed(1)}m`,
                                cx * scaleX,
                                cy * scaleY - 5
                            );
                        }
                    });
                }
                
                prevFrameData = currentFrameData;
                requestAnimationFrame(drawFrame);
            } else {
                // Display final statistics
                console.log('‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó');
                console.log('‚ïë CV TRACKING STATISTICS                    ‚ïë');
                console.log('‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£');
                console.log(`‚ïë Max tracked objects: ${trackingStats.maxObjects.toString().padEnd(22)}‚ïë`);
                console.log(`‚ïë Total frames: ${trackingStats.totalFrames.toString().padEnd(28)}‚ïë`);
                console.log('‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù');
            }
        }
        drawFrame();

        const canvasStream = canvas.captureStream(30);
        const processedBlob = engine.exportWAV();
        const audioURL = URL.createObjectURL(processedBlob);
        const audioElement = new Audio(audioURL);
        const audioContext = new AudioContext();
        const audioStream = audioContext.createMediaElementSource(audioElement);
        const destination = audioContext.createMediaStreamDestination();
        audioStream.connect(destination);

        const combinedStream = new MediaStream([
            ...canvasStream.getVideoTracks(),
            ...destination.stream.getAudioTracks()
        ]);

        mediaRecorder = new MediaRecorder(combinedStream, { mimeType: 'video/webm' });

        mediaRecorder.ondataavailable = event => {
            if (event.data.size > 0) {
                recordedChunks.push(event.data);
            }
        };

        mediaRecorder.onstop = () => {
            const blob = new Blob(recordedChunks, { type: 'video/webm' });
            const url = URL.createObjectURL(blob);
            const downloadLink = document.createElement('a');
            downloadLink.href = url;
            downloadLink.download = 'merged-video.webm';
            document.getElementById('downloadBtn').disabled = false;
            downloadLink.textContent = 'Download Merged Video';
            document.body.appendChild(downloadLink);
            downloadLink.click();
            document.body.removeChild(downloadLink);
            progressBarFill.style.width = '100%';
            progressBarFill.textContent = '100%';
            createVideoBtn.disabled = false;
            progressBar.style.display = 'none';
        };

        mediaRecorder.onstart = () => {
            audioElement.play();
            const duration = videoPreview.duration * 1000;
            const interval = setInterval(() => {
                const currentTime = videoPreview.currentTime * 1000;
                const progress = (currentTime / duration) * 100;
                progressBarFill.style.width = `${progress}%`;
                progressBarFill.textContent = `${Math.floor(progress)}%`;
                if (videoPreview.paused || videoPreview.ended) {
                    clearInterval(interval);
                }
            }, 100);
        };

        mediaRecorder.start();
        setTimeout(() => {
            mediaRecorder.stop();
            audioElement.pause();
        }, videoPreview.duration * 1000);
    });

    document.getElementById('roomPreset').onchange = (e) => {
        const presets = {
            bedroom: [4, 4, 2.5],
            living: [6, 8, 3],
            studio: [8, 10, 3],
            medium: [8, 6, 3.2],
            hall: [20, 25, 8]
        };
        const p = presets[e.target.value];
        if (p) {
            document.getElementById('roomWidth').value = p[0];
            document.getElementById('roomLength').value = p[1];
            document.getElementById('roomHeight').value = p[2];
            document.getElementById('roomWidthNum').value = p[0];
            document.getElementById('roomLengthNum').value = p[1];
            document.getElementById('roomHeightNum').value = p[2];
            document.getElementById('roomWidthValue').textContent = p[0] + 'm';
            document.getElementById('roomLengthValue').textContent = p[1] + 'm';
            document.getElementById('roomHeightValue').textContent = p[2] + 'm';
            const vol = (p[0] * p[1] * p[2]).toFixed(1);
            document.getElementById('roomVolume').textContent = vol + ' m¬≥';
        }
    };

    ['roomWidth', 'roomLength', 'roomHeight', 'wallReflectivity', 'airAbsorption'].forEach(id => {
        const slider = document.getElementById(id);
        const num = document.getElementById(id + 'Num');
        const display = document.getElementById(id + 'Value');

        slider.oninput = () => {
            num.value = slider.value;
            display.textContent = slider.value + (id.includes('room') ? 'm' : '');
        };

        num.oninput = () => {
            slider.value = num.value;
            display.textContent = num.value + (id.includes('room') ? 'm' : '');
        };
    });
});
    

